# The Dynamic Runtime Inlining (DRTI) project

With this project it is possible to take the output from an
[LLVM](http://llvm.org/) compiler such as
[clang](https://clang.llvm.org/) and allow selected parts of the code
to recompile themselves at runtime. This can inline function calls
made via function pointers including virtual function dispatch and
across shared-object boundaries. In these cases the targets of the
calls are generally known only at runtime, hence the name "Runtime
Inlining".

This is different to LLVM's [Link Time
Optimizations](https://www.llvm.org/docs/LinkTimeOptimization.html)
and can inline cases that LTO doesn't handle. It also **doesn't**
involve an LLVM bitcode **interpreter**; it runs native machine code
generated by Ahead of Time (AOT) compilation that can make calls to a
Just in Time (JIT) runtime compiler when needed.

The basic concept is to get the normal compiler front end like clang
to emit its LLVM Intermediate Representation (IR) as a bitcode file,
then run a custom LLVM pass over this to inject DRTI code at the
appropriate places. The custom pass also embeds the original bitcode
as a binary string in the output so that the bitcode is available at
runtime for recompilation. The command-line tool llc compiles the
adapted bitcode into a native object file.

Although the concept is fairly simple there were (and still are)
several challenges in its implementation. Currently the project is a
proof of concept, demonstrating that the idea can work, but not likely
to improve the speed of any real-world applications.

## Supported Platforms

For now the code only works on Linux on the x86-64 architecture. It is
dependent on version 9.0.1 of the LLVM libraries.

## Implementation

This section details some of the complexities of making DRTI work,
including some remaining areas for further development.

### Call-target identification

As mentioned in the introduction, DRTI has an ahead-of-time pass that
"decorates" functions in preparation for runtime inlining. However it
does **not** require that an entire program and all its libraries be
decorated. Decorated functions may call in to undecorated ones and
vice-versa.

The problem, then, is for one decorated function to discover when the
target of a function call is another decorated function. Or to put it
another way, two decorated functions have to be able to recognise an
edge between them in the call graph, but only when it is a **direct**
edge with no intervening calls. The second part is very important,
since a call chain from A* -> B -> C* (where only A* and C* are
decorated functions) must not result in mistakenly recompiling A with
a direct call to C.

Unfortunately that means that a simple solution such as using
Thread-Specific Storage to retain a DRTI call stack won't simply work,
because only decorated functions would update the state and
intermediate non-decorated functions would be difficult to detect.

I thought about this problem for a while and have come up with what I
believe is a robust mechanism for communication between decorated
functions. This is only partly implemented at the moment, for reasons
explained in the following description.

The first step is to find a register in which a decorated function can
pass a pointer to the latest node in the DRTI call tree.  Within the
Linux [x86-64 Application Binary
Interface](https://refspecs.linuxfoundation.org/elf/x86_64-abi-0.99.pdf)
(ABI) r12 to r15 are suitable. The other registers are not suitable
since they might be used already in the function call or in the case
of r11 can be overwritten before arriving at the called function. I've
chosen r14 to avoid unnecessary incompatibility with the [swiftcall
convention](https://clang.llvm.org/docs/AttributeReference.html#swift-context)
after coming across [D18092](https://reviews.llvm.org/D18092) and
[D18108](https://reviews.llvm.org/D18108).

The second and trickier part is to get a decorated function to
recognise when the r14 register is valid on entry, i.e. when the call
came directly from another decorated function. Perhaps surprisingly,
there is a way to do this by passing information via the return
address which is pushed onto the stack by the caller. The return
address normally points to the next instruction after a call, so if we
organise for the bytes preceding the return address to contain a
"magic" value, the callee can get the return address from the stack
and dereference it (minus an offset) to check for the magic
value. This assumes that the magic value could not occur in a real
call instruction, and also that the return address is not too close to
the start of a page boundary, since the preceding page isn't
guaranteed to be readable. If there are any other runtime
instrumentation systems using the same trick it would also require
that they choose a distinct magic value, of course.

This actually leaves one gap in the detection mechanism since an
undecorated function that "tail" calls a decorated function via a jump
does not push a return address; it leaves its own caller's return
address on top of the stack. So in the call chain A* -> B -> C* where
B -> C* is a jump rather than a call, C* would mistakenly conclude
that it had been called directly by A*. There is a way out of this
problem though, since B is required to preserve the callee-saved r14
register. This means that C* can safely read the call tree information
provided by A* and examine the final call's target address to
determine whether the call could have gone directly to C* or not. This
is made more complicated by the presence of the procedure linkage
table and virtual function call "thunks" but is doable.

In the existing proof-of-concept the tail-call detection is not yet
implemented but there is a test case in the code that demonstrates the
problem. The magic value is also stored slightly further away from the
return address than described above. That can be fixed by converting
call instructions into a push and jump, where the pushed return
address is a kind of return thunk which contains the magic value in
the intended place. Protection against unreadable preceding pages is
already implemented though, by forcing the return addresses to be
highly aligned. This means the return is either to the zeroth byte of
a page or sufficiently far into the page that the magic value is
guaranteed to be readable.

### Deciding what calls to inline

Currently the developer must provide an explicit list of functions to
be decorated by the DRTI pass. This is done via an environment
variable and/or a text file. All chains of three decorated functions
will be recompiled (once only) the first time the chain is discovered
at runtime.

In theory the explicit list is not necessary but doing without would
require significantly more work to reduce the overheads of the
injected code and to implement runtime heuristics to decide when to
recompile. There is some background on efficient implementation
techniques in the paper [Deriving Code Coverage Information from
Profiling Data Recorded for a Trace-based Just-in-time
Compiler](https://dl.acm.org/doi/pdf/10.1145/2500828.2500829) by
Christian Häubl, Christian Wimmer and Hanspeter Mössenböck.

### Call target replacement

DRTI does not have an implementation of "on-stack replacement". This
means that the only way that inlining can actually happen is where
there is a chain of at least three decorated calls. The first call has
to be decorated so that it can be retargeted to a recompiled version
of its target function, and that target function must make a call to
another decorated function that can be inlined during recompilation.

For example in chain of decorated calls A* -> B* -> C*, the
intermediate function B could be recompiled and inline the contents of
C. Then, assuming B* ever returns, A* could begin calling the
recompiled version of B with the inlined C.

This can probably be improved using something like the [stack
maps](http://llvm.org/docs/StackMaps.html) that were developed for the
WebKit JavaScript runtime compiler. As I understand it WebKit has
since moved away from using LLVM but the stack map code could probably
still be useful for DRTI.

### Deoptimization

### Virtual function calls
